---
layout: archive
---

{{ content }}

<meta itemprop="description" content="About me">

<div class="page__inner-wrap">
  <header></header>
  <section class="page__content">
    <p><strong>Welcome to my Webpage</strong></p>
    <p>I am a former Infantry Officer in the United States Army and a current Ph.D. candidate at Texas A&M University, where I research machine learning and its applications to healthcare under the guidance of <a href="https://people.tamu.edu/~tianbao-yang/">Dr. Tianbao Yang</a> and <a href="https://stmilab.github.io/">Dr. Bobak Mortazavi</a>. I am deeply passionate about exploring cutting-edge AI techniques that have the potential to improve health outcomes and enhance patient care. Studying a field that both fascinates me and has real-world impact is an incredible privilege.</p>

    <p><strong>Graduate Work</strong></p>

    <p>My research focuses on advancing machine learning methods for healthcare by leveraging electronic health record (EHR) data to develop predictive models for clinical decision support. I have pioneered bi-modal pretraining approaches that combine EHR time-series data with clinical notes using contrastive learning and masked reconstruction, demonstrating strong zero‐shot performance without the need for labeled data – as detailed in our recent paper on multimodal contrastive pretraining for medical time series and notes (<a href="https://arxiv.org/abs/2312.06855">paper</a>). My work also encompasses developing an EHR benchmark (<a href="https://openreview.net/forum?id=QWhce2zqne#discussion">paper</a>) to evaluate model transferability across diverse healthcare settings, and I am currently exploring lifelong learning strategies and unified training objectives to seamlessly integrate multiple data modalities. Additional recent publications include work on memory-efficient continual learning with CLIP models presented at the NeurIPS 2024 Workshop (<a href="https://openreview.net/forum?id=lLpTmQnapG&referrer=%5Bthe%20profile%20of%20Tianbao%20Yang%5D(%2Fprofile%3Fid%3D~Tianbao_Yang1)">paper</a>), an efficient contrastive unimodal pretraining method for EHR time series data accepted at the 2024 IEEE EMBS International Conference on Biomedical and Health Informatics (<a href="https://arxiv.org/abs/2410.09199">paper</a>), and a domain incremental continual learning benchmark for ICU time series model transportability (<a href="https://openreview.net/forum?id=QWhce2zqne#discussion">paper</a>).</p>

     <p>In addition to my research, I have had the honor of serving as the Instructor of Record for CSCE421: Machine Learning at Texas A&M University, where I developed a comprehensive curriculum for over 100 undergraduate students. This teaching experience has been incredibly rewarding, as it allowed me to share my passion for machine learning while nurturing the creativity and technical skills of the next generation of innovators.</p> 

     <p>I am also the creator and maintainer of (<a href="https://github.com/kingrc15/torchmimic"><strong>torchmimic</strong></a>), an open-source Python library designed to facilitate machine learning experiments on EHR data. Through torchmimic, and my contributions to related projects like (<a href="https://github.com/mmcdermott/MEDS_transforms/tree/main"><strong>meds-transforms</strong></a>) and (<a href="https://github.com/Oufattole/meds-torch"><strong>meds-torch</strong></a>), I strive to make advanced healthcare research more accessible and reproducible, empowering a broader community to drive innovation in this vital field.</p>



    <p><strong>Undergraduate Work</strong></p>

    <p>I have previously worked with <a href="https://vita-group.github.io/">Dr. Zhangyang "Atlas" Wang</a> on Unsupervised Learning and Neural Architecture Search. My Undergraduate Research Thesis was written with Dr Wang and Dr Mortazavi on "Boosting Partial Channel Neural Architecture Search with Gradient Projection." In this work we attemtpt to identify some issues that arise from disproportionate gradient flows through differentiable neural architecture cells. We try to address this issue with a multi-task learning method called gradient projection. In this thesis we show that our method can produce competitive results in half the time as the SOTA at the time.</p>

    <p>I also worked with <a href="https://ibt.tamu.edu/faculty/kurt-zhang.html">Dr. Ke "Kurt" Zhang</a> as an Undergraduate Research Assitant on Deep Gaussian Mixture Models for scRNA-seq data. We developed a Gaussian Mixture Variational Autoencoder that utilized Maximum Mean Discrepancy to merge batches. In addition, raw scRNA-seq data is represented as counts of gene expressions in cells which results in a large number of zero count data. Our model used a Decoder that was adapted to handle Zero Inflated Negative Binomial distributed data. I was a co-presenter at the Single Cell Omics Symposium this year where we presented a poster of our results and methods from this project. We are continuing to explore the applications of the method to overcome batch effect. </p>

    <p><strong>Before Computer Science</strong></p>

    <p>Before my obsession with Machine Learning, I attended Virginia Military Institute (VMI) and received a B.S. in Civil Engineering. During my time at VMI, I was able to become a certified EMT where I had the opportunity to learn about the medical world and help my community. In May of 2015 I graduated from VMI and received my commission as an Active Duty Army Infantry Officer. During my time in the Army, I was stationed at Fort Bliss with the 1st Armored Division. We deployed to Kuwait, Iraq and Syria in support of multiple overseas operations. In July of 2019, I got out of the Army and started my Undergraduate Degree in Computer Science at Texas A&M University.</p>
  </section>
</div>



